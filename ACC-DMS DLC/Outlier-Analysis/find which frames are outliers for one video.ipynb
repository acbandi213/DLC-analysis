{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acbandi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\statsmodels\\compat\\pandas.py:49: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  data_klasses = (pandas.Series, pandas.DataFrame, pandas.Panel)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import save\n",
    "import pandas as pd\n",
    "import glob\n",
    "import cv2  \n",
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "from ruamel.yaml import YAML\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"Y:\\DLC\\ACC_DMS_nphr_skeleton-acb-2020-09-14\"\n",
    "file_path2 = file_path + \"\\\\videos2\"\n",
    "\n",
    "path = r\"Y:\\DLC\\ACC_DMS_nphr_skeleton-acb-2020-09-14\\\\videos2\\\\*.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "##import config file info \n",
    "config = file_path + \"/config.yaml\"\n",
    "ruamelFile = YAML()\n",
    "cfg = ruamelFile.load(config)\n",
    "\n",
    "#bodyparts & relevant config data \n",
    "dataname = 'DLC_resnet50_ACC DMS nphr noskelSept21shuffle1_450000'\n",
    "bodyparts = ['Left Ear', 'Right Ear', 'Implant', 'Base of Tail', 'Nosepoke']\n",
    "p_bound = 0.01\n",
    "epsilon = 20 #number of pixel distance\n",
    "ARdegree=3\n",
    "MAdegree=1\n",
    "alpha=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertparms2start(pn):\n",
    "    \"\"\" Creating a start value for sarimax in case of an value error\n",
    "    See: https://groups.google.com/forum/#!topic/pystatsmodels/S_Fo53F25Rk \"\"\"\n",
    "    if \"ar.\" in pn:\n",
    "        return 0\n",
    "    elif \"ma.\" in pn:\n",
    "        return 0\n",
    "    elif \"sigma\" in pn:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def FitSARIMAXModel(x, p, pcutoff, alpha, ARdegree, MAdegree, nforecast=0, disp=False):\n",
    "    # Seasonal Autoregressive Integrated Moving-Average with eXogenous regressors (SARIMAX)\n",
    "    # see http://www.statsmodels.org/stable/statespace.html#seasonal-autoregressive-integrated-moving-average-with-exogenous-regressors-sarimax\n",
    "    Y = x.copy()\n",
    "    Y[p < pcutoff] = np.nan  # Set uncertain estimates to nan (modeled as missing data)\n",
    "    if np.sum(np.isfinite(Y)) > 10:\n",
    "\n",
    "        # SARIMAX implemetnation has better prediction models than simple ARIMAX (however we do not use the seasonal etc. parameters!)\n",
    "        mod = sm.tsa.statespace.SARIMAX(\n",
    "            Y.flatten(),\n",
    "            order=(ARdegree, 0, MAdegree),\n",
    "            seasonal_order=(0, 0, 0, 0),\n",
    "            simple_differencing=True,\n",
    "        )\n",
    "        # Autoregressive Moving Average ARMA(p,q) Model\n",
    "        # mod = sm.tsa.ARIMA(Y, order=(ARdegree,0,MAdegree)) #order=(ARdegree,0,MAdegree)\n",
    "        try:\n",
    "            res = mod.fit(disp=disp)\n",
    "        except ValueError:  # https://groups.google.com/forum/#!topic/pystatsmodels/S_Fo53F25Rk (let's update to statsmodels 0.10.0 soon...)\n",
    "            startvalues = np.array([convertparms2start(pn) for pn in mod.param_names])\n",
    "            res = mod.fit(start_params=startvalues, disp=disp)\n",
    "        except np.linalg.LinAlgError:\n",
    "            # The process is not stationary, but the default SARIMAX model tries to solve for such a distribution...\n",
    "            # Relaxing those constraints should do the job.\n",
    "            mod = sm.tsa.statespace.SARIMAX(\n",
    "                Y.flatten(),\n",
    "                order=(ARdegree, 0, MAdegree),\n",
    "                seasonal_order=(0, 0, 0, 0),\n",
    "                simple_differencing=True,\n",
    "                enforce_stationarity=False,\n",
    "                enforce_invertibility=False,\n",
    "                use_exact_diffuse=False,\n",
    "            )\n",
    "            res = mod.fit(disp=disp)\n",
    "\n",
    "        predict = res.get_prediction(end=mod.nobs + nforecast - 1)\n",
    "        return predict.predicted_mean, predict.conf_int(alpha=alpha)\n",
    "    else:\n",
    "        return np.nan * np.zeros(len(Y)), np.nan * np.zeros((len(Y), 2))\n",
    "\n",
    "def compute_deviations(Dataframe, dataname, p_bound, alpha, ARdegree, MAdegree, storeoutput=None):\n",
    "    \"\"\" Fits Seasonal AutoRegressive Integrated Moving Average with eXogenous regressors model to data and computes confidence interval\n",
    "    as well as mean fit. \"\"\"\n",
    "\n",
    "    print(\"Fitting state-space models with parameters:\", ARdegree, MAdegree)\n",
    "    df_x, df_y, df_likelihood = Dataframe.values.reshape((Dataframe.shape[0], -1, 3)).T\n",
    "    preds = []\n",
    "    for row in range(len(df_x)):\n",
    "        x = df_x[row]\n",
    "        y = df_y[row]\n",
    "        p = df_likelihood[row]\n",
    "        meanx, CIx = FitSARIMAXModel(x, p, p_bound, alpha, ARdegree, MAdegree)\n",
    "        meany, CIy = FitSARIMAXModel(y, p, p_bound, alpha, ARdegree, MAdegree)\n",
    "        distance = np.sqrt((x - meanx) ** 2 + (y - meany) ** 2)\n",
    "        significant = (\n",
    "            (x < CIx[:, 0]) + (x > CIx[:, 1]) + (x < CIy[:, 0]) + (y > CIy[:, 1])\n",
    "        )\n",
    "        preds.append(np.c_[distance, significant, meanx, meany, CIx, CIy])\n",
    "\n",
    "    columns = Dataframe.columns\n",
    "    prod = []\n",
    "    for i in range(columns.nlevels - 1):\n",
    "        prod.append(columns.get_level_values(i).unique())\n",
    "    prod.append(\n",
    "        [\n",
    "            \"distance\",\n",
    "            \"sig\",\n",
    "            \"meanx\",\n",
    "            \"meany\",\n",
    "            \"lowerCIx\",\n",
    "            \"higherCIx\",\n",
    "            \"lowerCIy\",\n",
    "            \"higherCIy\",\n",
    "        ]\n",
    "    )\n",
    "    pdindex = pd.MultiIndex.from_product(prod, names=columns.names)\n",
    "    data = pd.DataFrame(np.concatenate(preds, axis=1), columns=pdindex)\n",
    "    # average distance and average # significant differences avg. over comparisonbodyparts\n",
    "    d = data.xs(\"distance\", axis=1, level=-1).mean(axis=1).values\n",
    "    o = data.xs(\"sig\", axis=1, level=-1).mean(axis=1).values\n",
    "\n",
    "    if storeoutput == \"full\":\n",
    "        data.to_hdf(\n",
    "            dataname.split(\".h5\")[0] + \"filtered.h5\",\n",
    "            \"df_with_missing\",\n",
    "            format=\"table\",\n",
    "            mode=\"w\",\n",
    "        )\n",
    "        return d, o, data\n",
    "    else:\n",
    "        return d, o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions that make a dataframe of frame # listed as outlier \n",
    "\n",
    "def calc_uncertain(fname):\n",
    "    df = pd.read_hdf(fname) ##import data file \n",
    "        \n",
    "    nframes = len(df)\n",
    "    startindex = max([int(np.floor(nframes * 0)), 0])\n",
    "    stopindex = min([int(np.ceil(nframes * 1)), nframes])\n",
    "    Index = np.arange(stopindex - startindex) + startindex\n",
    "        \n",
    "    df = df.iloc[Index]\n",
    "    mask = df.columns.get_level_values(\"bodyparts\").isin(bodyparts)\n",
    "    df_temp = df.loc[:, mask] #temp df set up \n",
    "    \n",
    "    p = df_temp.xs(\"likelihood\", level=-1, axis=1)\n",
    "    pdf = pd.DataFrame(df_temp.index[(p < p_bound).any(axis=1)])\n",
    "    ind1 = pdf.values\n",
    "    \n",
    "    return ind1\n",
    "\n",
    "def calc_jump(fname):\n",
    "    df = pd.read_hdf(fname) ##import data file \n",
    "        \n",
    "    nframes = len(df)\n",
    "    startindex = max([int(np.floor(nframes * 0)), 0])\n",
    "    stopindex = min([int(np.ceil(nframes * 1)), nframes])\n",
    "    Index = np.arange(stopindex - startindex) + startindex\n",
    "        \n",
    "    df = df.iloc[Index]\n",
    "    mask = df.columns.get_level_values(\"bodyparts\").isin(bodyparts)\n",
    "    df_temp = df.loc[:, mask] #temp df set up \n",
    "    \n",
    "    temp_dt = df_temp.diff(axis=0) ** 2\n",
    "    temp_dt.drop(\"likelihood\", axis=1, level=-1, inplace=True)\n",
    "    sum_ = temp_dt.sum(axis=1, level=1)\n",
    "    sum_df = pd.DataFrame(df_temp.index[(sum_ > epsilon ** 2).any(axis=1)])\n",
    "    ind2 = sum_df.values\n",
    "    \n",
    "    return ind2\n",
    "\n",
    "def calc_fitting(fname):\n",
    "    df = pd.read_hdf(fname) ##import data file \n",
    "        \n",
    "    nframes = len(df)\n",
    "    startindex = max([int(np.floor(nframes * 0)), 0])\n",
    "    stopindex = min([int(np.ceil(nframes * 1)), nframes])\n",
    "    Index = np.arange(stopindex - startindex) + startindex\n",
    "        \n",
    "    df = df.iloc[Index]\n",
    "    mask = df.columns.get_level_values(\"bodyparts\").isin(bodyparts)\n",
    "    df_temp = df.loc[:, mask] #temp df set up \n",
    "   \n",
    "    warnings.simplefilter('ignore', ConvergenceWarning)\n",
    "    d, o = compute_deviations(df_temp, dataname, p_bound, alpha, ARdegree, MAdegree)\n",
    "    compute_df = pd.DataFrame(np.flatnonzero(d > epsilon))  # time points with at least average difference of epsilon\n",
    "    ind3 = compute_df.values \n",
    "    \n",
    "    return ind3\n",
    "\n",
    "def calculate_percent_outlier_frames(path):\n",
    "    for fname in glob.glob(path):\n",
    "        a = calc_uncertain(fname)\n",
    "        b = calc_jump(fname)\n",
    "        c = calc_fitting(fname)\n",
    "        os.chdir(file_path2)\n",
    "        save('uncertain_frames.npy', a)\n",
    "        save('jump_frames.npy', b)\n",
    "        save('fitting_frames.npy',c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting state-space models with parameters: 3 1\n"
     ]
    }
   ],
   "source": [
    "calculate_percent_outlier_frames(path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
